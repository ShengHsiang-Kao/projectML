{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import boston_housing\n",
    "from keras.datasets import reuters\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from keras import models,Model\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import cross_validate\n",
    "from utils import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1680 entries, 0 to 1686\n",
      "Data columns (total 8 columns):\n",
      "age                1680 non-null float64\n",
      "serveTime          1680 non-null float64\n",
      "credLimit          1680 non-null int64\n",
      "Loan               1680 non-null float64\n",
      "SalPerY            1680 non-null int64\n",
      "holdCard           1680 non-null int64\n",
      "Career             1680 non-null int64\n",
      "credLimit_group    1680 non-null int32\n",
      "dtypes: float64(3), int32(1), int64(4)\n",
      "memory usage: 111.6 KB\n"
     ]
    }
   ],
   "source": [
    "#開檔\n",
    "df = pd.read_excel(r'C:\\Users\\Big data\\Desktop\\class\\funcardproject\\斷詞與和卡額度_20群.xls',encoding='utf-16')\n",
    "df = df.loc[:, [\"age\",\"serveTime\",\"credLimit\",\"Loan\",\"SalPerY\",\"holdCard\",\"Career\",\"credLimit_group\"]] \n",
    "#若某raw有NAN則整RAW刪除\n",
    "df =df.dropna(\n",
    "    axis=0,     # 0: 对行进行操作; 1: 对列进行操作\n",
    "    how='any'   # 'any': 只要存在 NaN 就 drop 掉; 'all': 必须全部是 NaN 才 drop \n",
    "    ) \n",
    "#把分群的Y轉成int\n",
    "df['credLimit_group'] = df['credLimit_group'].astype('int')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1176, 6)\n",
      "(504, 6)\n",
      "(1176, 1)\n",
      "(504, 1)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_targets, test_targets = train_test_split(df.loc[:, [\"age\",\"serveTime\",\"Loan\",\"SalPerY\",\"holdCard\",\"Career\"]] , df.loc[:, [\"credLimit_group\"]] , test_size=0.3, random_state=42)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_targets.shape)\n",
    "print(test_targets.shape)\n",
    "#轉array\n",
    "train_data = np.array(train_data).astype(float)\n",
    "test_data = np.array(test_data).astype(float)\n",
    "train_targets = np.array(train_targets).astype(int)\n",
    "test_targets = np.array(test_targets).astype(int)\n",
    "#把Y弄成onehot\n",
    "def to_one_hot(labels, dimension=20):\n",
    "    results = np.zeros((len(labels),dimension))\n",
    "    for i,label in enumerate(labels):\n",
    "        results[i,label]=1.\n",
    "    return results\n",
    "train_targets = to_one_hot(train_targets)\n",
    "test_targets = to_one_hot(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1176, 6)\n",
      "(504, 6)\n",
      "(1176, 20)\n",
      "(504, 20)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "print(train_targets.shape)\n",
    "print(test_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#正規化\n",
    "#因為relu,所以這個比較好\n",
    "train_data_max = train_data.max(axis=0)\n",
    "train_data_min = train_data.min(axis=0)\n",
    "train_data_range = train_data_max-train_data_min\n",
    "train_data-=train_data_min\n",
    "train_data/=train_data_range\n",
    "\n",
    "test_data_max = test_data.max(axis=0)\n",
    "test_data_min = test_data.min(axis=0)\n",
    "test_data_range = test_data_max-test_data_min\n",
    "test_data-=test_data_min\n",
    "test_data/=test_data_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 6, 6)              36        \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1, 6)              222       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                140       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 398\n",
      "Trainable params: 398\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_CNN = Sequential()\n",
    "model_CNN.add(layers.Embedding(6,6,input_length=6))\n",
    "model_CNN.add(layers.Conv1D(6,6,activation='relu'))\n",
    "model_CNN.add(layers.GlobalMaxPool1D())\n",
    "model_CNN.add(layers.Dense(20))\n",
    "model_CNN.add(Activation('softmax'))\n",
    "model_CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 12)                288       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                260       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 548\n",
      "Trainable params: 548\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_GRU = Sequential()\n",
    "model_GRU.add(layers.Bidirectional(layers.GRU(6),input_shape=(6,1)))\n",
    "model_GRU.add(layers.Dense(20))\n",
    "model_GRU.add(Activation('softmax'))\n",
    "model_GRU.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一般的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 30)                210       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 25)                775       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                520       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 20)                420       \n",
      "=================================================================\n",
      "Total params: 1,925\n",
      "Trainable params: 1,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#模型定義\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(30, activation='relu',input_shape=(6 , )))\n",
    "model.add(layers.Dense(25, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='relu'))\n",
    "model.add(layers.Dense(20, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_129 (Dense)               (None, 3)            21          input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_130 (Dense)               (None, 20)           80          dense_129[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_131 (Dense)               (None, 4)            28          input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_133 (Dense)               (None, 5)            35          input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 20)           0           dense_130[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_132 (Dense)               (None, 20)           100         dense_131[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_134 (Dense)               (None, 20)           120         dense_133[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 60)           0           dropout_18[0][0]                 \n",
      "                                                                 dense_132[0][0]                  \n",
      "                                                                 dense_134[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_135 (Dense)               (None, 20)           1220        concatenate_17[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,604\n",
      "Trainable params: 1,604\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1176 samples, validate on 504 samples\n",
      "Epoch 1/100\n",
      "1176/1176 [==============================] - 0s 133us/step - loss: 3.1088 - accuracy: 0.0323 - val_loss: 3.0605 - val_accuracy: 0.0357\n",
      "Epoch 2/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 3.0169 - accuracy: 0.0323 - val_loss: 2.9746 - val_accuracy: 0.0357\n",
      "Epoch 3/100\n",
      "1176/1176 [==============================] - 0s 13us/step - loss: 2.9340 - accuracy: 0.0323 - val_loss: 2.8956 - val_accuracy: 0.0357\n",
      "Epoch 4/100\n",
      "1176/1176 [==============================] - 0s 16us/step - loss: 2.8577 - accuracy: 0.2143 - val_loss: 2.8238 - val_accuracy: 0.2460\n",
      "Epoch 5/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.7879 - accuracy: 0.2670 - val_loss: 2.7561 - val_accuracy: 0.2599\n",
      "Epoch 6/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.7233 - accuracy: 0.2704 - val_loss: 2.6978 - val_accuracy: 0.2599\n",
      "Epoch 7/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.6645 - accuracy: 0.2704 - val_loss: 2.6421 - val_accuracy: 0.2599\n",
      "Epoch 8/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.6116 - accuracy: 0.2704 - val_loss: 2.5907 - val_accuracy: 0.2599\n",
      "Epoch 9/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.5662 - accuracy: 0.2704 - val_loss: 2.5455 - val_accuracy: 0.2599\n",
      "Epoch 10/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.5222 - accuracy: 0.2704 - val_loss: 2.5051 - val_accuracy: 0.2599\n",
      "Epoch 11/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.4815 - accuracy: 0.2704 - val_loss: 2.4673 - val_accuracy: 0.2599\n",
      "Epoch 12/100\n",
      "1176/1176 [==============================] - 0s 17us/step - loss: 2.4462 - accuracy: 0.2704 - val_loss: 2.4342 - val_accuracy: 0.2599\n",
      "Epoch 13/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.4148 - accuracy: 0.2704 - val_loss: 2.4043 - val_accuracy: 0.2599\n",
      "Epoch 14/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.3872 - accuracy: 0.2704 - val_loss: 2.3776 - val_accuracy: 0.2599\n",
      "Epoch 15/100\n",
      "1176/1176 [==============================] - 0s 18us/step - loss: 2.3610 - accuracy: 0.2704 - val_loss: 2.3534 - val_accuracy: 0.2599\n",
      "Epoch 16/100\n",
      "1176/1176 [==============================] - 0s 20us/step - loss: 2.3357 - accuracy: 0.2704 - val_loss: 2.3316 - val_accuracy: 0.2599\n",
      "Epoch 17/100\n",
      "1176/1176 [==============================] - 0s 16us/step - loss: 2.3174 - accuracy: 0.2704 - val_loss: 2.3110 - val_accuracy: 0.2599\n",
      "Epoch 18/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.3034 - accuracy: 0.2704 - val_loss: 2.2928 - val_accuracy: 0.2599\n",
      "Epoch 19/100\n",
      "1176/1176 [==============================] - 0s 16us/step - loss: 2.2824 - accuracy: 0.2704 - val_loss: 2.2761 - val_accuracy: 0.2599\n",
      "Epoch 20/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.2666 - accuracy: 0.2704 - val_loss: 2.2608 - val_accuracy: 0.2599\n",
      "Epoch 21/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.2537 - accuracy: 0.2704 - val_loss: 2.2463 - val_accuracy: 0.2599\n",
      "Epoch 22/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.2384 - accuracy: 0.2704 - val_loss: 2.2326 - val_accuracy: 0.2599\n",
      "Epoch 23/100\n",
      "1176/1176 [==============================] - 0s 16us/step - loss: 2.2252 - accuracy: 0.2704 - val_loss: 2.2210 - val_accuracy: 0.2599\n",
      "Epoch 24/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.2180 - accuracy: 0.2704 - val_loss: 2.2103 - val_accuracy: 0.2599\n",
      "Epoch 25/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.2091 - accuracy: 0.2704 - val_loss: 2.2006 - val_accuracy: 0.2599\n",
      "Epoch 26/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.2001 - accuracy: 0.2704 - val_loss: 2.1912 - val_accuracy: 0.2599\n",
      "Epoch 27/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.1889 - accuracy: 0.2704 - val_loss: 2.1827 - val_accuracy: 0.2599\n",
      "Epoch 28/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.1803 - accuracy: 0.2704 - val_loss: 2.1749 - val_accuracy: 0.2599\n",
      "Epoch 29/100\n",
      "1176/1176 [==============================] - 0s 18us/step - loss: 2.1746 - accuracy: 0.2704 - val_loss: 2.1673 - val_accuracy: 0.2599\n",
      "Epoch 30/100\n",
      "1176/1176 [==============================] - 0s 16us/step - loss: 2.1692 - accuracy: 0.2704 - val_loss: 2.1608 - val_accuracy: 0.2599\n",
      "Epoch 31/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.1603 - accuracy: 0.2704 - val_loss: 2.1542 - val_accuracy: 0.2599\n",
      "Epoch 32/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.1555 - accuracy: 0.2704 - val_loss: 2.1487 - val_accuracy: 0.2599\n",
      "Epoch 33/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.1476 - accuracy: 0.2704 - val_loss: 2.1432 - val_accuracy: 0.2599\n",
      "Epoch 34/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.1444 - accuracy: 0.2704 - val_loss: 2.1383 - val_accuracy: 0.2599\n",
      "Epoch 35/100\n",
      "1176/1176 [==============================] - 0s 16us/step - loss: 2.1402 - accuracy: 0.2704 - val_loss: 2.1336 - val_accuracy: 0.2599\n",
      "Epoch 36/100\n",
      "1176/1176 [==============================] - 0s 16us/step - loss: 2.1364 - accuracy: 0.2704 - val_loss: 2.1290 - val_accuracy: 0.2599\n",
      "Epoch 37/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.1286 - accuracy: 0.2704 - val_loss: 2.1248 - val_accuracy: 0.2599\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1176/1176 [==============================] - 0s 16us/step - loss: 2.1263 - accuracy: 0.2704 - val_loss: 2.1208 - val_accuracy: 0.2599\n",
      "Epoch 39/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.1211 - accuracy: 0.2704 - val_loss: 2.1170 - val_accuracy: 0.2599\n",
      "Epoch 40/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.1193 - accuracy: 0.2704 - val_loss: 2.1132 - val_accuracy: 0.2599\n",
      "Epoch 41/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.1142 - accuracy: 0.2704 - val_loss: 2.1098 - val_accuracy: 0.2599\n",
      "Epoch 42/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.1125 - accuracy: 0.2704 - val_loss: 2.1065 - val_accuracy: 0.2599\n",
      "Epoch 43/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.1087 - accuracy: 0.2704 - val_loss: 2.1033 - val_accuracy: 0.2599\n",
      "Epoch 44/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.1080 - accuracy: 0.2704 - val_loss: 2.1001 - val_accuracy: 0.2599\n",
      "Epoch 45/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.1009 - accuracy: 0.2704 - val_loss: 2.0971 - val_accuracy: 0.2599\n",
      "Epoch 46/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.1035 - accuracy: 0.2704 - val_loss: 2.0948 - val_accuracy: 0.2599\n",
      "Epoch 47/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0984 - accuracy: 0.2704 - val_loss: 2.0927 - val_accuracy: 0.2599\n",
      "Epoch 48/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0948 - accuracy: 0.2704 - val_loss: 2.0902 - val_accuracy: 0.2599\n",
      "Epoch 49/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0986 - accuracy: 0.2704 - val_loss: 2.0880 - val_accuracy: 0.2599\n",
      "Epoch 50/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0880 - accuracy: 0.2704 - val_loss: 2.0859 - val_accuracy: 0.2599\n",
      "Epoch 51/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0868 - accuracy: 0.2704 - val_loss: 2.0838 - val_accuracy: 0.2599\n",
      "Epoch 52/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0855 - accuracy: 0.2704 - val_loss: 2.0818 - val_accuracy: 0.2599\n",
      "Epoch 53/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0894 - accuracy: 0.2704 - val_loss: 2.0798 - val_accuracy: 0.2599\n",
      "Epoch 54/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0841 - accuracy: 0.2704 - val_loss: 2.0779 - val_accuracy: 0.2599\n",
      "Epoch 55/100\n",
      "1176/1176 [==============================] - 0s 19us/step - loss: 2.0850 - accuracy: 0.2704 - val_loss: 2.0763 - val_accuracy: 0.2599\n",
      "Epoch 56/100\n",
      "1176/1176 [==============================] - 0s 17us/step - loss: 2.0796 - accuracy: 0.2704 - val_loss: 2.0744 - val_accuracy: 0.2599\n",
      "Epoch 57/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0805 - accuracy: 0.2704 - val_loss: 2.0724 - val_accuracy: 0.2599\n",
      "Epoch 58/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0783 - accuracy: 0.2704 - val_loss: 2.0710 - val_accuracy: 0.2599\n",
      "Epoch 59/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0766 - accuracy: 0.2704 - val_loss: 2.0693 - val_accuracy: 0.2599\n",
      "Epoch 60/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0726 - accuracy: 0.2713 - val_loss: 2.0678 - val_accuracy: 0.2599\n",
      "Epoch 61/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0744 - accuracy: 0.2704 - val_loss: 2.0665 - val_accuracy: 0.2599\n",
      "Epoch 62/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0719 - accuracy: 0.2696 - val_loss: 2.0652 - val_accuracy: 0.2599\n",
      "Epoch 63/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0730 - accuracy: 0.2713 - val_loss: 2.0643 - val_accuracy: 0.2599\n",
      "Epoch 64/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0703 - accuracy: 0.2704 - val_loss: 2.0630 - val_accuracy: 0.2599\n",
      "Epoch 65/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0691 - accuracy: 0.2704 - val_loss: 2.0617 - val_accuracy: 0.2599\n",
      "Epoch 66/100\n",
      "1176/1176 [==============================] - 0s 17us/step - loss: 2.0658 - accuracy: 0.2721 - val_loss: 2.0606 - val_accuracy: 0.2599\n",
      "Epoch 67/100\n",
      "1176/1176 [==============================] - 0s 16us/step - loss: 2.0694 - accuracy: 0.2704 - val_loss: 2.0595 - val_accuracy: 0.2599\n",
      "Epoch 68/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0690 - accuracy: 0.2713 - val_loss: 2.0586 - val_accuracy: 0.2599\n",
      "Epoch 69/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0650 - accuracy: 0.2696 - val_loss: 2.0574 - val_accuracy: 0.2599\n",
      "Epoch 70/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0581 - accuracy: 0.2713 - val_loss: 2.0565 - val_accuracy: 0.2599\n",
      "Epoch 71/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0651 - accuracy: 0.2713 - val_loss: 2.0552 - val_accuracy: 0.2599\n",
      "Epoch 72/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0572 - accuracy: 0.2696 - val_loss: 2.0542 - val_accuracy: 0.2599\n",
      "Epoch 73/100\n",
      "1176/1176 [==============================] - 0s 16us/step - loss: 2.0580 - accuracy: 0.2704 - val_loss: 2.0536 - val_accuracy: 0.2599\n",
      "Epoch 74/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0603 - accuracy: 0.2704 - val_loss: 2.0527 - val_accuracy: 0.2599\n",
      "Epoch 75/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0588 - accuracy: 0.2704 - val_loss: 2.0519 - val_accuracy: 0.2599\n",
      "Epoch 76/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0563 - accuracy: 0.2704 - val_loss: 2.0509 - val_accuracy: 0.2599\n",
      "Epoch 77/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0559 - accuracy: 0.2704 - val_loss: 2.0501 - val_accuracy: 0.2599\n",
      "Epoch 78/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0571 - accuracy: 0.2696 - val_loss: 2.0494 - val_accuracy: 0.2599\n",
      "Epoch 79/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0542 - accuracy: 0.2721 - val_loss: 2.0486 - val_accuracy: 0.2599\n",
      "Epoch 80/100\n",
      "1176/1176 [==============================] - 0s 16us/step - loss: 2.0527 - accuracy: 0.2704 - val_loss: 2.0477 - val_accuracy: 0.2599\n",
      "Epoch 81/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0582 - accuracy: 0.2704 - val_loss: 2.0470 - val_accuracy: 0.2599\n",
      "Epoch 82/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0529 - accuracy: 0.2704 - val_loss: 2.0462 - val_accuracy: 0.2599\n",
      "Epoch 83/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0493 - accuracy: 0.2704 - val_loss: 2.0456 - val_accuracy: 0.2599\n",
      "Epoch 84/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0540 - accuracy: 0.2704 - val_loss: 2.0448 - val_accuracy: 0.2599\n",
      "Epoch 85/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0505 - accuracy: 0.2704 - val_loss: 2.0442 - val_accuracy: 0.2599\n",
      "Epoch 86/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0463 - accuracy: 0.2713 - val_loss: 2.0436 - val_accuracy: 0.2599\n",
      "Epoch 87/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0495 - accuracy: 0.2679 - val_loss: 2.0430 - val_accuracy: 0.2599\n",
      "Epoch 88/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0513 - accuracy: 0.2713 - val_loss: 2.0424 - val_accuracy: 0.2599\n",
      "Epoch 89/100\n",
      "1176/1176 [==============================] - 0s 15us/step - loss: 2.0451 - accuracy: 0.2713 - val_loss: 2.0418 - val_accuracy: 0.2599\n",
      "Epoch 90/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0467 - accuracy: 0.2704 - val_loss: 2.0412 - val_accuracy: 0.2599\n",
      "Epoch 91/100\n",
      "1176/1176 [==============================] - 0s 16us/step - loss: 2.0507 - accuracy: 0.2704 - val_loss: 2.0405 - val_accuracy: 0.2599\n",
      "Epoch 92/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0463 - accuracy: 0.2696 - val_loss: 2.0401 - val_accuracy: 0.2599\n",
      "Epoch 93/100\n",
      "1176/1176 [==============================] - 0s 16us/step - loss: 2.0449 - accuracy: 0.2696 - val_loss: 2.0398 - val_accuracy: 0.2599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0432 - accuracy: 0.2696 - val_loss: 2.0394 - val_accuracy: 0.2599\n",
      "Epoch 95/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0451 - accuracy: 0.2721 - val_loss: 2.0387 - val_accuracy: 0.2599\n",
      "Epoch 96/100\n",
      "1176/1176 [==============================] - 0s 13us/step - loss: 2.0445 - accuracy: 0.2704 - val_loss: 2.0384 - val_accuracy: 0.2599\n",
      "Epoch 97/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0387 - accuracy: 0.2704 - val_loss: 2.0380 - val_accuracy: 0.2599\n",
      "Epoch 98/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0444 - accuracy: 0.2704 - val_loss: 2.0374 - val_accuracy: 0.2599\n",
      "Epoch 99/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0424 - accuracy: 0.2713 - val_loss: 2.0370 - val_accuracy: 0.2599\n",
      "Epoch 100/100\n",
      "1176/1176 [==============================] - 0s 14us/step - loss: 2.0446 - accuracy: 0.2679 - val_loss: 2.0364 - val_accuracy: 0.2599\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "inputs = Input(shape=(6,))\n",
    "x = Dense(3, activation='tanh',kernel_initializer='random_uniform')(inputs)\n",
    "x = Dense(20, activation='tanh')(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "y = Dense(4, activation='sigmoid')(inputs)\n",
    "y = Dense(20, activation='sigmoid')(y)\n",
    "\n",
    "z = Dense(5, activation='relu')(inputs)\n",
    "z = Dense(20, activation='relu')(z)\n",
    "\n",
    "\n",
    "merged  = concatenate([x, y,z], axis=1)\n",
    "output = Dense(20, activation='softmax')(merged )\n",
    "model = Model(inputs=inputs, outputs=output)\n",
    "\n",
    "sgd = optimizers.SGD(lr=0.01, momentum=0.01, decay=0.001, nesterov=False)\n",
    "model.summary()\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_data,train_targets,\n",
    "                   epochs=100,\n",
    "                   batch_size=128,\n",
    "                   validation_data=(test_data,test_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35347 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 32244 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 33287 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 39511 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 35657 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 25613 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 22833 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:211: RuntimeWarning: Glyph 25976 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35347 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 32244 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 33287 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 39511 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 35657 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 30340 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 25613 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 22833 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 20989 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:180: RuntimeWarning: Glyph 25976 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#繪圖\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss)+ 1)\n",
    "plt.plot(epochs, loss,'bo',label='Training loss')\n",
    "plt.plot(epochs, val_loss,'b',label='Validation loss')\n",
    "plt.title('訓練與驗證的損失函數')\n",
    "plt.xlabel('Epohs')\n",
    "plt.xlabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "acc = history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo',label='Training acc')\n",
    "plt.plot(epochs, val_acc,'b',label='Validation acc')\n",
    "plt.title('TAT')\n",
    "plt.xlabel('Epohs')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(inp):#重新建立模型，与原来不一样的是这里inp是传入\n",
    "    n_classes = 10\n",
    "    #inp=Input(shape=(120,39))#原来的inp是函数里，传入可以三个公用\n",
    "    reshape=Reshape((1,120,39))(inp)\n",
    " #   pre=ZeroPadding2D(padding=(1, 1))(reshape)\n",
    "    # 1\n",
    "    #reshape=BatchNormalization()(reshape)\n",
    "    conv1=Convolution2D(32, 3, 3, border_mode='same',init='glorot_uniform')(reshape)\n",
    "    #model.add(Activation('relu'))\n",
    "    l1=PReLU()(conv1)\n",
    "    l1=BatchNormalization()(l1)\n",
    " \n",
    "    conv2=ZeroPadding2D(padding=(1, 1))(l1)\n",
    "    conv2=Convolution2D(32, 3, 3, border_mode='same',init='glorot_uniform')(conv2)\n",
    "    #model.add(Activation('relu'))\n",
    "    l2=PReLU()(conv2)\n",
    "    l2=BatchNormalization()(l2)\n",
    " \n",
    "    m2=AveragePooling2D((3, 3), strides=(3, 3))(l2)\n",
    "    d2=Dropout(0.25)(m2)\n",
    "    # 2\n",
    "    conv3=ZeroPadding2D(padding=(1, 1))(d2)\n",
    "    conv3=Convolution2D(64, 3, 3, border_mode='same',init='glorot_uniform')(conv3)\n",
    "    #model.add(Activation('relu'))\n",
    "    l3=PReLU()(conv3)\n",
    "    l3=BatchNormalization()(l3)\n",
    " \n",
    "    conv4=ZeroPadding2D(padding=(1, 1))(l3)\n",
    "    conv4=Convolution2D(64, 3, 3, border_mode='same',init='glorot_uniform')(conv4)\n",
    "    #model.add(Activation('relu'))\n",
    "    l4=PReLU()(conv4)\n",
    "    l4=BatchNormalization()(l4)\n",
    " \n",
    "    m4=AveragePooling2D((3, 3), strides=(3, 3))(l4)\n",
    "    d4=Dropout(0.25)(m4)\n",
    "    \n",
    "    g=GlobalAveragePooling2D()(d4)\n",
    "#4\n",
    "#    conv4=Convolution2D(32, 3, 3, border_mode='same',init='glorot_uniform')(d3)\n",
    "#    conv4=BatchNormalization()(conv4)\n",
    "#    #model.add(Activation('relu'))\n",
    "#    l4=LeakyReLU(alpha=0.33)(conv4)\n",
    "#    m4=MaxPooling2D((2, 2))(l4)\n",
    "#    d4=Dropout(0.25)(m4)\n",
    "    \n",
    "    #f=Flatten()(g)\n",
    "    Den=Dense(1024)(g)\n",
    "    #model.add(Activation('relu'))\n",
    "    ld=PReLU()(Den)\n",
    "    ld=Dropout(0.5)(ld)\n",
    "    result=Dense(n_classes, activation='softmax')(ld)\n",
    " \n",
    " \n",
    " \n",
    "    model=Model(input=inp,outputs=result)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def merge_model():\n",
    "    inp=Input(shape=(120,39))#融合主要就是Input是同样的，所以重新建立模型\n",
    "    model1=get_model(inp)\n",
    "    model2=get_model(inp)\n",
    "    model3=get_model(inp)\n",
    "    model1.load_weights(model_path+\"CNN_mfcc1.h5\")#加载各自权重\n",
    "    model2.load_weights(model_path+\"CNN_mfcc2.h5\")#加载各自权重\n",
    "    model3.load_weights(model_path+\"CNN_mfcc3.h5\")#加载各自权重\n",
    "    \n",
    "    r1=model1.output#获得输出\n",
    "    r2=model2.output\n",
    "    r3=model3.output\n",
    "    \n",
    "    x=concatenate([r1,r2,r3],axis=1)#拼接输出，融合成功\n",
    "    model=Model(input=inp,outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'origin_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0f54e6ff15f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morigin_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morigin_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mden\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"fine_dense\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'origin_model' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "inp=origin_model.input\n",
    "x=origin_model.output\n",
    "\n",
    "den=Dense(200,name=\"fine_dense\")(x)\n",
    "l=PReLU()(den)\n",
    "l=Dropout(0.5)(l)\n",
    "result=Dense(10,activation=\"softmax\")(l)\n",
    "\n",
    "model=Model(input=inp,outputs=result)\n",
    "model.summary()\n",
    "#编译model\n",
    "adam = keras.optimizers.Adam(lr = 0.0005, beta_1=0.95, beta_2=0.999,epsilon=1e-08)\n",
    "#adam = keras.optimizers.Adam(lr = 0.001, beta_1=0.95, beta_2=0.999,epsilon=1e-08)\n",
    "#sgd = keras.optimizers.SGD(lr = 0.001, decay = 1e-06, momentum = 0.9, nesterov = False)\n",
    "\n",
    "#reduce_lr = ReduceLROnPlateau(monitor = 'loss', factor = 0.1, patience = 2,verbose = 1, min_lr = 0.00000001, mode = 'min')\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(6,))\n",
    "\n",
    "# a layer instance is callable on a tensor, and returns a tensor\n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "predictions = Dense(20, activation='softmax')(x)\n",
    "\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_data,train_targets,\n",
    "                   epochs=20,\n",
    "                   batch_size=32,\n",
    "                   validation_data=(test_data,test_targets))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
